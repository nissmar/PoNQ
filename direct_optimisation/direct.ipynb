{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimizes point with chamfer, distance to vstars, repulsion. Reconstruction using mean normal and taku itoh. Kind of works excpet for sparse sampling / many details "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rvd_dual:\n",
    "- the \"networks\" outputs positions p, normals n and quadrics q  (from the voronoi region)\n",
    "- Compute v*\n",
    "- Build the Delaunay/Voronoi of v*\n",
    "- Select all tets which circumcenter are inside the 4 half spaces defined by v*(ind) and n(ind)\n",
    "- output boundary of tets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "sys.path.insert(1, '../utils/')\n",
    "import neural_quadrics as nq\n",
    "import mesh_tools as mt\n",
    "import torch\n",
    "from torch import nn\n",
    "from tqdm import tqdm\n",
    "from pytorch3d.loss import chamfer_distance\n",
    "from meshplot import plot\n",
    "from IPython.display import clear_output\n",
    "import os\n",
    "import trimesh\n",
    "from pytorch3d.ops import knn_points\n",
    "from direct import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_N = 32\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "# model_name = '../../data/thingy32/groundtruths/441708.stl' #bunny\n",
    "# model_name = '../../data/thingy32/groundtruths/527631.stl'\n",
    "model_name = '../../data/thingy32/groundtruths/95444.stl'\n",
    "model_name = '../../data/thingy32/groundtruths/47984.stl'\n",
    "# model_name = '/data/nmaruani/DATASETS/fun/spearman.stl'\n",
    "\n",
    "# model_name = '/data/nmaruani/DATASETS/fun/ActionChess_-_Pawn_B_x6.stl'\n",
    "# model_name = '/data/nmaruani/DATASETS/fun/cubeminus.obj'\n",
    "\n",
    "input_points, input_normals = mt.load_shape(model_name, normalize='NDC', sample_n=int(1.5e5*GRID_N**2/32**2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = mt.mesh_grid(GRID_N, True)\n",
    "V = nq.MovingQuadrics(points[mt.mask_relevant_voxels(GRID_N, input_points)], device)\n",
    "\n",
    "optimizer = torch.optim.Adam([V.points], 1e-3/(GRID_N/32))\n",
    "\n",
    "\n",
    "tensor_surface = torch.tensor(input_points, dtype=torch.float32).to(device)\n",
    "tensor_normals = torch.tensor(input_normals, dtype=torch.float32).to(device)\n",
    "L=[]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(V, optimizer, tensor_surface, repulsion_fac=0, sample_fac=1):\n",
    "    optimizer.zero_grad()\n",
    "    masks = torch.rand_like(tensor_surface[:, 0]) < sample_fac\n",
    "    loss = chamfer_distance(\n",
    "        tensor_surface[masks][None, :], V.points[None, :])[0].mean()\n",
    "    if repulsion_fac > 0:\n",
    "        min_dist = knn_points(V.points[None, :], V.points[None, :], K=2).dists[0, :, 1]**2\n",
    "        loss += -repulsion_fac * min_dist.mean()\n",
    "    x = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(200)):\n",
    "    L.append((train_simple(V, optimizer, tensor_surface, repulsion_fac=0, sample_fac=.1)))\n",
    "    \n",
    "        # scheduler.step()\n",
    "plt.plot(L)\n",
    "plt.yscale('log')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RVD dual Mesh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V.cluster_samples_quadrics_normals(tensor_surface, tensor_normals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(*V.quadric_ellipse_mesh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "nv, nf = V.min_cut_surface(32)\n",
    "\n",
    "mp = plot(nv,nf, shading={'wireframe': True})\n",
    "# mp.add_mesh(*V.quadric_ellipse_mesh())\n",
    "# meshplot_add_points(mp, voronoi.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nv.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export_obj(*rvd_dual(V, tensor_surface, tensor_normals), 'pn_bunny')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch RVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simple(V, repulsion_fac=0, sample_fac=1):\n",
    "    optimizer.zero_grad()\n",
    "    masks = torch.rand_like(tensor_surface[:, 0]) < sample_fac\n",
    "    loss = chamfer_distance(tensor_surface[masks][None,:], V.points[None,:])[0].mean()\n",
    "    if repulsion_fac>0:\n",
    "        loss += -repulsion_fac*(V.distance_to_centroids(V.points,V.points).topk(2, 0, False).values[1].mean())\n",
    "\n",
    "    # quadrics = V.cluster_samples_quadrics(tensor_surface, tensor_normals)\n",
    "    # vstars, _, _, mask_exist = vstars_from_quadrics(quadrics, V.points)\n",
    "    # loss += ((V.points[mask_exist]-vstars)**2).sum(-1).mean()\n",
    "    x = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step() \n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GRID_N = 128\n",
    "\n",
    "src_dir = '../../data/thingy32/groundtruths/'\n",
    "for model_name in tqdm(os.listdir(src_dir)):\n",
    "    v, f = mt.load_and_sample_shape(model_name, src_dir, 0, 'NDC')\n",
    "    ref_mesh = trimesh.Trimesh(v,f)\n",
    "    samples, face_index = trimesh.sample.sample_surface_even(ref_mesh, int(1e5*GRID_N**2/32**2))\n",
    "    samples = np.array(samples)\n",
    "    normals = np.array(ref_mesh.face_normals[face_index])\n",
    "\n",
    "    points = mt.mesh_grid(GRID_N, True)\n",
    "    V = nq.MovingQuadrics(points[mt.mask_relevant_voxels(GRID_N, samples)], device)\n",
    "    global optimizer\n",
    "    optimizer = None\n",
    "    def reset_optimizer(lr=.005):\n",
    "        global optimizer\n",
    "        optimizer = torch.optim.Adam([V.points], lr)\n",
    "    reset_optimizer()\n",
    "\n",
    "    tensor_surface = torch.tensor(samples, dtype=torch.float32).to(device)\n",
    "    tensor_normals = torch.tensor(normals, dtype=torch.float32).to(device)\n",
    "    for i in (range(200)):\n",
    "        train_simple(V, repulsion_fac=0, sample_fac=1)\n",
    "    V.cluster_samples_quadrics_normals(tensor_surface, tensor_normals)\n",
    "    torch.save(V, 'rvd_dual_{}/{}.pt'.format(GRID_N, model_name[:-4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V = torch.load('rvd_dual_64/44234.pt')\n",
    "plot(*V.rvd_dual())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edge flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(*V.quadric_ellipse_mesh(size=0.02, lambd=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = igl.edges(nf)\n",
    "mid_points = np.ones((len(edges), 4))\n",
    "mid_points[:, :3] = nv[edges].mean(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_score = (mid_points[:, None, :]@quadrics[edges[:, 0]].cpu().detach().numpy()@mid_points[:, :, None]).squeeze()\n",
    "mid_score += (mid_points[:, None, :]@quadrics[edges[:, 1]].cpu().detach().numpy()@mid_points[:, :, None]).squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../configs/direct_thingi.yaml', 'r') as f:\n",
    "    cfg = yaml.load(f, Loader=yaml.Loader)\n",
    "\n",
    "\n",
    "cfg['io']['grid_n'] = 64\n",
    "cfg['path']['out_dir'] = cfg['path']['out_dir'].format(\n",
    "    cfg['io']['grid_n'])\n",
    "cfg['io']['sample_n'] = int(\n",
    "    cfg['io']['sample_n_base'] * (cfg['io']['grid_n']/32)**2)\n",
    "cfg['optim']['lr'] = cfg['optim']['lr_base']/(cfg['io']['grid_n']/32)\n",
    "L = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = '../../data/thingy32/groundtruths/47984.stl'\n",
    "\n",
    "input_points, input_normals = mt.load_shape(model_path, cfg['io']['in_pointcloud'], cfg['io']['normalize'], cfg['io']['sample_n'])\n",
    "\n",
    "if cfg['model']['init'] == 'farthest' or not (32 is None):\n",
    "    input_pc = input_points\n",
    "else:\n",
    "    input_pc = None\n",
    "\n",
    "V = initialize_model(cfg['model']['n_points'],\n",
    "                        cfg['optim']['device'], input_pc, cfg['io']['grid_n'])\n",
    "\n",
    "optimizer = torch.optim.Adam([V.points], cfg['optim']['lr'])\n",
    "\n",
    "tensor_surface = torch.tensor(\n",
    "    input_points, dtype=torch.float32).to(cfg['optim']['device'])\n",
    "tensor_normals = torch.tensor(\n",
    "    input_normals, dtype=torch.float32).to(cfg['optim']['device'])\n",
    "\n",
    "for _ in tqdm(range(cfg['optim']['epochs'])):\n",
    "    L.append(train_simple(\n",
    "        V, optimizer, tensor_surface, repulsion_fac=cfg['optim']['repulsion_fac'], sample_fac=cfg['optim']['sample_fac']))\n",
    "\n",
    "# RVD dual Mesh\n",
    "V.cluster_samples_quadrics_normals(tensor_surface, tensor_normals)\n",
    "\n",
    "# # Save output\n",
    "# save_output(V, cfg['path']['out_dir'], name[:-4], cfg['io']\n",
    "#             ['out_pt'], cfg['io']['out_rvd'], cfg['io']['out_poisson'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_output()\n",
    "nv, nf = V.rvd_dual()\n",
    "mp = plot(nv,nf, shading={'wireframe': True})\n",
    "# mp.add_mesh(*V.quadric_ellipse_mesh())\n",
    "# meshplot_add_points(mp, voronoi.vertices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('inria')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "58e83627acc6d058f657b0f6d5867b185d1a1a7149f889eec0a18761397c5507"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
